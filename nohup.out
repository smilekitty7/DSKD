2022-08-02 11:33:15,286 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda-11.1
NVCC: Build cuda_11.1.TC455_06.29190527_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04) 9.4.0
PyTorch: 1.7.1+cu110
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2+cu110
OpenCV: 4.5.5
MMCV: 1.3.14
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.1
MMDetection: 2.23.0+90a7c74
------------------------------------------------------------

2022-08-02 11:33:27,588 - mmdet - INFO - Distributed training: True


======== Task-1(Task1) 开始, At 2022-08-02 11:33:39.415290 ==========
2022-08-02 11:33:39,656 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/home/softlink/dataset/COCO2017/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
img_scale_size1 = [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640]
img_scale_size2 = [
    320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768,
    800
]
img_scale_size3 = [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]
img_scale_size = [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640]
max_min_size = (640, 640)
train_pipeline_singlescale = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='Resize',
        img_scale=(640, 640),
        multiscale_mode='range',
        keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_pipeline_multiscale = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='Resize',
        img_scale=[(320, 320), (320, 352), (320, 384), (320, 416), (320, 448),
                   (320, 480), (320, 512), (320, 544), (320, 576), (320, 608),
                   (320, 640), (352, 320), (352, 352), (352, 384), (352, 416),
                   (352, 448), (352, 480), (352, 512), (352, 544), (352, 576),
                   (352, 608), (352, 640), (384, 320), (384, 352), (384, 384),
                   (384, 416), (384, 448), (384, 480), (384, 512), (384, 544),
                   (384, 576), (384, 608), (384, 640), (416, 320), (416, 352),
                   (416, 384), (416, 416), (416, 448), (416, 480), (416, 512),
                   (416, 544), (416, 576), (416, 608), (416, 640), (448, 320),
                   (448, 352), (448, 384), (448, 416), (448, 448), (448, 480),
                   (448, 512), (448, 544), (448, 576), (448, 608), (448, 640),
                   (480, 320), (480, 352), (480, 384), (480, 416), (480, 448),
                   (480, 480), (480, 512), (480, 544), (480, 576), (480, 608),
                   (480, 640), (512, 320), (512, 352), (512, 384), (512, 416),
                   (512, 448), (512, 480), (512, 512), (512, 544), (512, 576),
                   (512, 608), (512, 640), (544, 320), (544, 352), (544, 384),
                   (544, 416), (544, 448), (544, 480), (544, 512), (544, 544),
                   (544, 576), (544, 608), (544, 640), (576, 320), (576, 352),
                   (576, 384), (576, 416), (576, 448), (576, 480), (576, 512),
                   (576, 544), (576, 576), (576, 608), (576, 640), (608, 320),
                   (608, 352), (608, 384), (608, 416), (608, 448), (608, 480),
                   (608, 512), (608, 544), (608, 576), (608, 608), (608, 640),
                   (640, 320), (640, 352), (640, 384), (640, 416), (640, 448),
                   (640, 480), (640, 512), (640, 544), (640, 576), (640, 608),
                   (640, 640)],
        multiscale_mode='value',
        keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_pipeline_phdrccms = [
    dict(type='LoadImageFromFile', to_float32=True, color_type='color'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='PhotoMetricDistortion',
        brightness_delta=32,
        contrast_range=(0.5, 1.5),
        saturation_range=(0.5, 1.5),
        hue_delta=18),
    dict(
        type='RandomCenterCropPad',
        crop_size=(640, 640),
        ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),
        mean=[0, 0, 0],
        std=[1, 1, 1],
        to_rgb=True,
        test_pad_mode=None),
    dict(type='Resize', img_scale=(640, 640), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_pipeline_albmscale = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='Resize',
        img_scale=[(320, 320), (320, 352), (320, 384), (320, 416), (320, 448),
                   (320, 480), (320, 512), (320, 544), (320, 576), (320, 608),
                   (320, 640), (352, 320), (352, 352), (352, 384), (352, 416),
                   (352, 448), (352, 480), (352, 512), (352, 544), (352, 576),
                   (352, 608), (352, 640), (384, 320), (384, 352), (384, 384),
                   (384, 416), (384, 448), (384, 480), (384, 512), (384, 544),
                   (384, 576), (384, 608), (384, 640), (416, 320), (416, 352),
                   (416, 384), (416, 416), (416, 448), (416, 480), (416, 512),
                   (416, 544), (416, 576), (416, 608), (416, 640), (448, 320),
                   (448, 352), (448, 384), (448, 416), (448, 448), (448, 480),
                   (448, 512), (448, 544), (448, 576), (448, 608), (448, 640),
                   (480, 320), (480, 352), (480, 384), (480, 416), (480, 448),
                   (480, 480), (480, 512), (480, 544), (480, 576), (480, 608),
                   (480, 640), (512, 320), (512, 352), (512, 384), (512, 416),
                   (512, 448), (512, 480), (512, 512), (512, 544), (512, 576),
                   (512, 608), (512, 640), (544, 320), (544, 352), (544, 384),
                   (544, 416), (544, 448), (544, 480), (544, 512), (544, 544),
                   (544, 576), (544, 608), (544, 640), (576, 320), (576, 352),
                   (576, 384), (576, 416), (576, 448), (576, 480), (576, 512),
                   (576, 544), (576, 576), (576, 608), (576, 640), (608, 320),
                   (608, 352), (608, 384), (608, 416), (608, 448), (608, 480),
                   (608, 512), (608, 544), (608, 576), (608, 608), (608, 640),
                   (640, 320), (640, 352), (640, 384), (640, 416), (640, 448),
                   (640, 480), (640, 512), (640, 544), (640, 576), (640, 608),
                   (640, 640)],
        multiscale_mode='value',
        keep_ratio=True),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(
                        type='RandomBrightnessContrast',
                        brightness_limit=[-0.3, 0.3],
                        contrast_limit=[-0.3, 0.3],
                        p=1),
                    dict(
                        type='ColorJitter',
                        brightness=0.2,
                        contrast=0.2,
                        saturation=0.2,
                        hue=0.2,
                        always_apply=False,
                        p=1)
                ],
                p=0.3),
            dict(
                type='OneOf',
                transforms=[
                    dict(
                        type='GaussNoise',
                        var_limit=(30.0, 80.0),
                        mean=0,
                        per_channel=True,
                        always_apply=False,
                        p=1),
                    dict(type='MotionBlur', blur_limit=(3, 12), p=1)
                ],
                p=0.3),
            dict(
                type='Cutout',
                num_holes=72,
                max_h_size=16,
                max_w_size=16,
                fill_value=123,
                always_apply=False,
                p=0.3)
        ],
        bbox_params=None,
        keymap=None,
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline_singlescale = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(640, 640),
        flip=False,
        transforms=[
            dict(type='Resize', multiscale_mode='range', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
test_pipeline_multiscale = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=[(320, 320), (320, 352), (320, 384), (320, 416), (320, 448),
                   (320, 480), (320, 512), (320, 544), (320, 576), (320, 608),
                   (320, 640), (352, 320), (352, 352), (352, 384), (352, 416),
                   (352, 448), (352, 480), (352, 512), (352, 544), (352, 576),
                   (352, 608), (352, 640), (384, 320), (384, 352), (384, 384),
                   (384, 416), (384, 448), (384, 480), (384, 512), (384, 544),
                   (384, 576), (384, 608), (384, 640), (416, 320), (416, 352),
                   (416, 384), (416, 416), (416, 448), (416, 480), (416, 512),
                   (416, 544), (416, 576), (416, 608), (416, 640), (448, 320),
                   (448, 352), (448, 384), (448, 416), (448, 448), (448, 480),
                   (448, 512), (448, 544), (448, 576), (448, 608), (448, 640),
                   (480, 320), (480, 352), (480, 384), (480, 416), (480, 448),
                   (480, 480), (480, 512), (480, 544), (480, 576), (480, 608),
                   (480, 640), (512, 320), (512, 352), (512, 384), (512, 416),
                   (512, 448), (512, 480), (512, 512), (512, 544), (512, 576),
                   (512, 608), (512, 640), (544, 320), (544, 352), (544, 384),
                   (544, 416), (544, 448), (544, 480), (544, 512), (544, 544),
                   (544, 576), (544, 608), (544, 640), (576, 320), (576, 352),
                   (576, 384), (576, 416), (576, 448), (576, 480), (576, 512),
                   (576, 544), (576, 576), (576, 608), (576, 640), (608, 320),
                   (608, 352), (608, 384), (608, 416), (608, 448), (608, 480),
                   (608, 512), (608, 544), (608, 576), (608, 608), (608, 640),
                   (640, 320), (640, 352), (640, 384), (640, 416), (640, 448),
                   (640, 480), (640, 512), (640, 544), (640, 576), (640, 608),
                   (640, 640)],
        flip=True,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Resize', img_scale=(640, 640), keep_ratio=True),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=1),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(640, 640),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=1),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
which = ['', '_mini1k', '_mini2k', '_mini5k', '_mini2w', '_mini3w', '_mini5w']
trainwhich = ''
valwhich = ''
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file=
        '/home/softlink/dataset/COCO2017/annotations/instances_train2017.json',
        img_prefix='/home/softlink/dataset/COCO2017/train2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='Resize',
                img_scale=(640, 640),
                multiscale_mode='range',
                keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ],
        test_mode=False,
        catsplit=(40, 40),
        catload=(1, 0),
        catpred='prev-cur',
        catwise=True,
        imgpercent=1),
    val=dict(
        type='CocoDataset',
        ann_file=
        '/home/softlink/dataset/COCO2017/annotations/instances_val2017.json',
        img_prefix='/home/softlink/dataset/COCO2017/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(640, 640),
                flip=False,
                transforms=[
                    dict(
                        type='Resize',
                        multiscale_mode='range',
                        keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        test_mode=True,
        catsplit=(40, 40),
        catload=(1, 0),
        catpred='only-cur',
        catwise=True,
        imgpercent=1),
    test=dict(
        type='CocoDataset',
        ann_file=
        '/home/softlink/dataset/COCO2017/annotations/instances_val2017.json',
        img_prefix='/home/softlink/dataset/COCO2017/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(640, 640),
                flip=False,
                transforms=[
                    dict(
                        type='Resize',
                        multiscale_mode='range',
                        keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        test_mode=True,
        catsplit=(40, 40),
        catload=(1, 0),
        catpred='prev-cur',
        catwise=True,
        imgpercent=1),
    cat_split_load='auto')
evaluation = dict(interval=1, metric='bbox')
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=1,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = ''
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
task = dict(
    resume_by_task=1,
    resume_by_epoch='',
    Task1=dict(
        load_teacher=0,
        load_student=1,
        teacher_config=
        '/home/kangmx/project/incremental_mmdet/configs/deformable_detr/gfl_deformable_detr_r50_8x4_1x_qoqo_il_local.py',
        teacher_ckpt=
        '/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth',
        student_ckpt=
        '/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth'
    ))
model = dict(
    type='DeformableDETR_il',
    teacher_config=None,
    teacher_ckpt=None,
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=False),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(
            type='Pretrained',
            checkpoint='/home/softlink/Pretrained/resnet50-19c8e357.pth')),
    neck=dict(
        type='ChannelMapper',
        in_channels=[512, 1024, 2048],
        kernel_size=1,
        out_channels=256,
        act_cfg=None,
        norm_cfg=dict(type='GN', num_groups=32),
        num_outs=4),
    bbox_head=dict(
        type='GFLDeformableDETRHead_il',
        num_query=300,
        num_classes=80,
        in_channels=2048,
        sync_cls_avg_factor=True,
        as_two_stage=False,
        transformer=dict(
            type='DeformableDetrTransformer',
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention', embed_dims=256),
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'ffn', 'norm'))),
            decoder=dict(
                type='DeformableDetrTransformerDecoder',
                num_layers=6,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='MultiScaleDeformableAttention',
                            embed_dims=256)
                    ],
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='QualityFocalLoss',
            use_sigmoid=True,
            beta=2.0,
            loss_weight=2.0),
        loss_dfl=dict(type='DistributionFocalLoss', loss_weight=0.5),
        loss_bbox=dict(type='L1Loss', loss_weight=5.0),
        loss_iou=dict(type='GIoULoss', loss_weight=2.0),
        cates_distill='hard + teacher-first',
        locat_distill='',
        memory_distill='',
        feats_distill='corr',
        loss_kd=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='mean'),
        loss_ld_bbox=dict(
            type='SmoothL1Loss', loss_weight=10, reduction='mean'),
        loss_ld_logit=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='mean'),
        loss_fd=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_memory=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_fg_feature=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_bg_feature=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_corr=dict(type='MSELoss', loss_weight=1, reduction='mean')),
    train_cfg=dict(
        assigner=dict(
            type='GFLHungarianAssigner',
            cls_cost=dict(type='QualityFocalLossCost', weight=2.0),
            reg_cost=dict(type='BBoxL1Cost', weight=5.0, box_format='xywh'),
            iou_cost=dict(type='IoUCost', iou_mode='giou', weight=2.0))),
    test_cfg=dict(max_per_img=100, score_thr=0.0),
    teacher_test_cfg=dict(min_bbox_size=0, score_thr=0.3, max_per_img=100))
catsplit = (40, 40)
catload = (1, 0)
cat_split_load = 'auto'
task_nums = 2
optimizer = [
    dict(type='SGD', lr=0.0, momentum=0.9, weight_decay=0.0001),
    dict(type='SGD', lr=0.0, momentum=0.9, weight_decay=0.0001)
]
optimizer_config = dict(grad_clip=None)
lr_config = [
    dict(
        policy='step',
        warmup='linear',
        warmup_iters=1500,
        warmup_ratio=0.01,
        step=[8, 11]),
    dict(
        policy='step',
        warmup='linear',
        warmup_iters=1500,
        warmup_ratio=0.01,
        step=[8, 11])
]
runner = [
    dict(
        type='TaskEpochBasedRunner',
        max_epochs=12,
        max_tasks=2,
        save_teacher=False),
    dict(
        type='TaskEpochBasedRunner',
        max_epochs=12,
        max_tasks=2,
        save_teacher=False)
]
work_dir = '/home/softlink/experiments/il_learning/gfl_deformable_detr_20_3/'
auto_resume = False
gpu_ids = range(0, 4)

2022-08-02 11:33:39,657 - mmdet - INFO - Set random seed to 111, deterministic: False


======== Task-1(Task1) 开始, At 2022-08-02 11:33:39.657982 ==========
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '


======== Task-1(Task1) 开始, At 2022-08-02 11:33:39.989889 ==========
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
教师模型未设置，teacher_config=None，teacher_ckpt=None
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
教师模型未设置，teacher_config=None，teacher_ckpt=None
2022-08-02 11:33:40,568 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': '/home/softlink/Pretrained/resnet50-19c8e357.pth'}
2022-08-02 11:33:40,569 - mmcv - INFO - load model from: /home/softlink/Pretrained/resnet50-19c8e357.pth
2022-08-02 11:33:40,569 - mmcv - INFO - Use load_from_local loader


======== Task-1(Task1) 开始, At 2022-08-02 11:33:40.589011 ==========
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
2022-08-02 11:33:40,796 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2022-08-02 11:33:40,834 - mmdet - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
教师模型未设置，teacher_config=None，teacher_ckpt=None
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:33:41.134445 ==========
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
The model and loaded state dict do not match exactly

missing keys in source state_dict: bbox_head.prototype.weight

教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:33:41.418326 ==========
教师模型未设置，teacher_config=None，teacher_ckpt=None
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:33:41.746877 ==========
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:33:42.429884 ==========
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
Done (t=16.17s)
creating index...
Done (t=16.82s)
creating index...
Done (t=16.67s)
creating index...
Done (t=16.04s)
creating index...
index created!
DataIL: 当前加载图像数量为：95846 张！
index created!
DataIL: 当前加载图像数量为：95846 张！
index created!
DataIL: 当前加载图像数量为：95846 张！
index created!
DataIL: 当前加载图像数量为：95846 张！

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
Done (t=0.49s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
Done (t=0.52s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！
Done (t=0.50s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！

Task-2 训练图像数量: 95846 & 验证图像数量: 4952

Done (t=0.52s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！

Task-2 训练图像数量: 95846 & 验证图像数量: 4952

Task-2 训练图像数量: 95846 & 验证图像数量: 4952

Task-2 训练图像数量: 95846 & 验证图像数量: 4952



2022-08-02 11:34:03,253 - mmdet - INFO - Start running, host: kangmx@xlab2, work_dir: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_3
2022-08-02 11:34:03,254 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2022-08-02 11:34:03,254 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
Traceback (most recent call last):
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/subprocess.py", line 1019, in wait
    return self._wait(timeout=timeout)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/subprocess.py", line 1653, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/subprocess.py", line 1611, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
运行总时间: 0 小时，36 分钟.
2022-08-02 11:36:18,904 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda-11.1
NVCC: Build cuda_11.1.TC455_06.29190527_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04) 9.4.0
PyTorch: 1.7.1+cu110
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2+cu110
OpenCV: 4.5.5
MMCV: 1.3.14
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.1
MMDetection: 2.23.0+90a7c74
------------------------------------------------------------

2022-08-02 11:36:31,054 - mmdet - INFO - Distributed training: True


======== Task-1(Task1) 开始, At 2022-08-02 11:36:43.102235 ==========
2022-08-02 11:36:43,292 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/home/softlink/dataset/COCO2017/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
img_scale_size1 = [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640]
img_scale_size2 = [
    320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768,
    800
]
img_scale_size3 = [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]
img_scale_size = [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640]
max_min_size = (640, 640)
train_pipeline_singlescale = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='Resize',
        img_scale=(640, 640),
        multiscale_mode='range',
        keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_pipeline_multiscale = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='Resize',
        img_scale=[(320, 320), (320, 352), (320, 384), (320, 416), (320, 448),
                   (320, 480), (320, 512), (320, 544), (320, 576), (320, 608),
                   (320, 640), (352, 320), (352, 352), (352, 384), (352, 416),
                   (352, 448), (352, 480), (352, 512), (352, 544), (352, 576),
                   (352, 608), (352, 640), (384, 320), (384, 352), (384, 384),
                   (384, 416), (384, 448), (384, 480), (384, 512), (384, 544),
                   (384, 576), (384, 608), (384, 640), (416, 320), (416, 352),
                   (416, 384), (416, 416), (416, 448), (416, 480), (416, 512),
                   (416, 544), (416, 576), (416, 608), (416, 640), (448, 320),
                   (448, 352), (448, 384), (448, 416), (448, 448), (448, 480),
                   (448, 512), (448, 544), (448, 576), (448, 608), (448, 640),
                   (480, 320), (480, 352), (480, 384), (480, 416), (480, 448),
                   (480, 480), (480, 512), (480, 544), (480, 576), (480, 608),
                   (480, 640), (512, 320), (512, 352), (512, 384), (512, 416),
                   (512, 448), (512, 480), (512, 512), (512, 544), (512, 576),
                   (512, 608), (512, 640), (544, 320), (544, 352), (544, 384),
                   (544, 416), (544, 448), (544, 480), (544, 512), (544, 544),
                   (544, 576), (544, 608), (544, 640), (576, 320), (576, 352),
                   (576, 384), (576, 416), (576, 448), (576, 480), (576, 512),
                   (576, 544), (576, 576), (576, 608), (576, 640), (608, 320),
                   (608, 352), (608, 384), (608, 416), (608, 448), (608, 480),
                   (608, 512), (608, 544), (608, 576), (608, 608), (608, 640),
                   (640, 320), (640, 352), (640, 384), (640, 416), (640, 448),
                   (640, 480), (640, 512), (640, 544), (640, 576), (640, 608),
                   (640, 640)],
        multiscale_mode='value',
        keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_pipeline_phdrccms = [
    dict(type='LoadImageFromFile', to_float32=True, color_type='color'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='PhotoMetricDistortion',
        brightness_delta=32,
        contrast_range=(0.5, 1.5),
        saturation_range=(0.5, 1.5),
        hue_delta=18),
    dict(
        type='RandomCenterCropPad',
        crop_size=(640, 640),
        ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),
        mean=[0, 0, 0],
        std=[1, 1, 1],
        to_rgb=True,
        test_pad_mode=None),
    dict(type='Resize', img_scale=(640, 640), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_pipeline_albmscale = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='Resize',
        img_scale=[(320, 320), (320, 352), (320, 384), (320, 416), (320, 448),
                   (320, 480), (320, 512), (320, 544), (320, 576), (320, 608),
                   (320, 640), (352, 320), (352, 352), (352, 384), (352, 416),
                   (352, 448), (352, 480), (352, 512), (352, 544), (352, 576),
                   (352, 608), (352, 640), (384, 320), (384, 352), (384, 384),
                   (384, 416), (384, 448), (384, 480), (384, 512), (384, 544),
                   (384, 576), (384, 608), (384, 640), (416, 320), (416, 352),
                   (416, 384), (416, 416), (416, 448), (416, 480), (416, 512),
                   (416, 544), (416, 576), (416, 608), (416, 640), (448, 320),
                   (448, 352), (448, 384), (448, 416), (448, 448), (448, 480),
                   (448, 512), (448, 544), (448, 576), (448, 608), (448, 640),
                   (480, 320), (480, 352), (480, 384), (480, 416), (480, 448),
                   (480, 480), (480, 512), (480, 544), (480, 576), (480, 608),
                   (480, 640), (512, 320), (512, 352), (512, 384), (512, 416),
                   (512, 448), (512, 480), (512, 512), (512, 544), (512, 576),
                   (512, 608), (512, 640), (544, 320), (544, 352), (544, 384),
                   (544, 416), (544, 448), (544, 480), (544, 512), (544, 544),
                   (544, 576), (544, 608), (544, 640), (576, 320), (576, 352),
                   (576, 384), (576, 416), (576, 448), (576, 480), (576, 512),
                   (576, 544), (576, 576), (576, 608), (576, 640), (608, 320),
                   (608, 352), (608, 384), (608, 416), (608, 448), (608, 480),
                   (608, 512), (608, 544), (608, 576), (608, 608), (608, 640),
                   (640, 320), (640, 352), (640, 384), (640, 416), (640, 448),
                   (640, 480), (640, 512), (640, 544), (640, 576), (640, 608),
                   (640, 640)],
        multiscale_mode='value',
        keep_ratio=True),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(
                        type='RandomBrightnessContrast',
                        brightness_limit=[-0.3, 0.3],
                        contrast_limit=[-0.3, 0.3],
                        p=1),
                    dict(
                        type='ColorJitter',
                        brightness=0.2,
                        contrast=0.2,
                        saturation=0.2,
                        hue=0.2,
                        always_apply=False,
                        p=1)
                ],
                p=0.3),
            dict(
                type='OneOf',
                transforms=[
                    dict(
                        type='GaussNoise',
                        var_limit=(30.0, 80.0),
                        mean=0,
                        per_channel=True,
                        always_apply=False,
                        p=1),
                    dict(type='MotionBlur', blur_limit=(3, 12), p=1)
                ],
                p=0.3),
            dict(
                type='Cutout',
                num_holes=72,
                max_h_size=16,
                max_w_size=16,
                fill_value=123,
                always_apply=False,
                p=0.3)
        ],
        bbox_params=None,
        keymap=None,
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline_singlescale = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(640, 640),
        flip=False,
        transforms=[
            dict(type='Resize', multiscale_mode='range', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
test_pipeline_multiscale = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=[(320, 320), (320, 352), (320, 384), (320, 416), (320, 448),
                   (320, 480), (320, 512), (320, 544), (320, 576), (320, 608),
                   (320, 640), (352, 320), (352, 352), (352, 384), (352, 416),
                   (352, 448), (352, 480), (352, 512), (352, 544), (352, 576),
                   (352, 608), (352, 640), (384, 320), (384, 352), (384, 384),
                   (384, 416), (384, 448), (384, 480), (384, 512), (384, 544),
                   (384, 576), (384, 608), (384, 640), (416, 320), (416, 352),
                   (416, 384), (416, 416), (416, 448), (416, 480), (416, 512),
                   (416, 544), (416, 576), (416, 608), (416, 640), (448, 320),
                   (448, 352), (448, 384), (448, 416), (448, 448), (448, 480),
                   (448, 512), (448, 544), (448, 576), (448, 608), (448, 640),
                   (480, 320), (480, 352), (480, 384), (480, 416), (480, 448),
                   (480, 480), (480, 512), (480, 544), (480, 576), (480, 608),
                   (480, 640), (512, 320), (512, 352), (512, 384), (512, 416),
                   (512, 448), (512, 480), (512, 512), (512, 544), (512, 576),
                   (512, 608), (512, 640), (544, 320), (544, 352), (544, 384),
                   (544, 416), (544, 448), (544, 480), (544, 512), (544, 544),
                   (544, 576), (544, 608), (544, 640), (576, 320), (576, 352),
                   (576, 384), (576, 416), (576, 448), (576, 480), (576, 512),
                   (576, 544), (576, 576), (576, 608), (576, 640), (608, 320),
                   (608, 352), (608, 384), (608, 416), (608, 448), (608, 480),
                   (608, 512), (608, 544), (608, 576), (608, 608), (608, 640),
                   (640, 320), (640, 352), (640, 384), (640, 416), (640, 448),
                   (640, 480), (640, 512), (640, 544), (640, 576), (640, 608),
                   (640, 640)],
        flip=True,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Resize', img_scale=(640, 640), keep_ratio=True),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=1),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(640, 640),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=1),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
which = ['', '_mini1k', '_mini2k', '_mini5k', '_mini2w', '_mini3w', '_mini5w']
trainwhich = ''
valwhich = ''
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file=
        '/home/softlink/dataset/COCO2017/annotations/instances_train2017.json',
        img_prefix='/home/softlink/dataset/COCO2017/train2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='Resize',
                img_scale=(640, 640),
                multiscale_mode='range',
                keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ],
        test_mode=False,
        catsplit=(40, 40),
        catload=(1, 0),
        catpred='prev-cur',
        catwise=True,
        imgpercent=1),
    val=dict(
        type='CocoDataset',
        ann_file=
        '/home/softlink/dataset/COCO2017/annotations/instances_val2017.json',
        img_prefix='/home/softlink/dataset/COCO2017/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(640, 640),
                flip=False,
                transforms=[
                    dict(
                        type='Resize',
                        multiscale_mode='range',
                        keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        test_mode=True,
        catsplit=(40, 40),
        catload=(1, 0),
        catpred='only-cur',
        catwise=True,
        imgpercent=1),
    test=dict(
        type='CocoDataset',
        ann_file=
        '/home/softlink/dataset/COCO2017/annotations/instances_val2017.json',
        img_prefix='/home/softlink/dataset/COCO2017/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(640, 640),
                flip=False,
                transforms=[
                    dict(
                        type='Resize',
                        multiscale_mode='range',
                        keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        test_mode=True,
        catsplit=(40, 40),
        catload=(1, 0),
        catpred='prev-cur',
        catwise=True,
        imgpercent=1),
    cat_split_load='auto')
evaluation = dict(interval=1, metric='bbox')
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=1,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = ''
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
task = dict(
    resume_by_task=1,
    resume_by_epoch='',
    Task1=dict(
        load_teacher=0,
        load_student=1,
        teacher_config=
        '/home/kangmx/project/incremental_mmdet/configs/deformable_detr/gfl_deformable_detr_r50_8x4_1x_qoqo_il_local.py',
        teacher_ckpt=
        '/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth',
        student_ckpt=
        '/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth'
    ))
model = dict(
    type='DeformableDETR_il',
    teacher_config=None,
    teacher_ckpt=None,
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=False),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(
            type='Pretrained',
            checkpoint='/home/softlink/Pretrained/resnet50-19c8e357.pth')),
    neck=dict(
        type='ChannelMapper',
        in_channels=[512, 1024, 2048],
        kernel_size=1,
        out_channels=256,
        act_cfg=None,
        norm_cfg=dict(type='GN', num_groups=32),
        num_outs=4),
    bbox_head=dict(
        type='GFLDeformableDETRHead_il',
        num_query=300,
        num_classes=80,
        in_channels=2048,
        sync_cls_avg_factor=True,
        as_two_stage=False,
        transformer=dict(
            type='DeformableDetrTransformer',
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention', embed_dims=256),
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'ffn', 'norm'))),
            decoder=dict(
                type='DeformableDetrTransformerDecoder',
                num_layers=6,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='MultiScaleDeformableAttention',
                            embed_dims=256)
                    ],
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='QualityFocalLoss',
            use_sigmoid=True,
            beta=2.0,
            loss_weight=2.0),
        loss_dfl=dict(type='DistributionFocalLoss', loss_weight=0.5),
        loss_bbox=dict(type='L1Loss', loss_weight=5.0),
        loss_iou=dict(type='GIoULoss', loss_weight=2.0),
        cates_distill='hard + teacher-first',
        locat_distill='',
        memory_distill='',
        feats_distill='corr',
        loss_kd=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='mean'),
        loss_ld_bbox=dict(
            type='SmoothL1Loss', loss_weight=10, reduction='mean'),
        loss_ld_logit=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='mean'),
        loss_fd=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_memory=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_fg_feature=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_bg_feature=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_corr=dict(type='MSELoss', loss_weight=1, reduction='mean')),
    train_cfg=dict(
        assigner=dict(
            type='GFLHungarianAssigner',
            cls_cost=dict(type='QualityFocalLossCost', weight=2.0),
            reg_cost=dict(type='BBoxL1Cost', weight=5.0, box_format='xywh'),
            iou_cost=dict(type='IoUCost', iou_mode='giou', weight=2.0))),
    test_cfg=dict(max_per_img=100, score_thr=0.0),
    teacher_test_cfg=dict(min_bbox_size=0, score_thr=0.3, max_per_img=100))
catsplit = (40, 40)
catload = (1, 0)
cat_split_load = 'auto'
task_nums = 2
optimizer = [
    dict(type='SGD', lr=0.0, momentum=0.9, weight_decay=0.0001),
    dict(type='SGD', lr=0.0, momentum=0.9, weight_decay=0.0001)
]
optimizer_config = dict(grad_clip=None)
lr_config = [
    dict(
        policy='step',
        warmup='linear',
        warmup_iters=1500,
        warmup_ratio=0.01,
        step=[8, 11]),
    dict(
        policy='step',
        warmup='linear',
        warmup_iters=1500,
        warmup_ratio=0.01,
        step=[8, 11])
]
runner = [
    dict(
        type='TaskEpochBasedRunner',
        max_epochs=12,
        max_tasks=2,
        save_teacher=False),
    dict(
        type='TaskEpochBasedRunner',
        max_epochs=12,
        max_tasks=2,
        save_teacher=False)
]
work_dir = '/home/softlink/experiments/il_learning/gfl_deformable_detr_20_3/'
auto_resume = False
gpu_ids = range(0, 4)

2022-08-02 11:36:43,293 - mmdet - INFO - Set random seed to 111, deterministic: False


======== Task-1(Task1) 开始, At 2022-08-02 11:36:43.293651 ==========


======== Task-1(Task1) 开始, At 2022-08-02 11:36:43.314162 ==========
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
教师模型未设置，teacher_config=None，teacher_ckpt=None


======== Task-1(Task1) 开始, At 2022-08-02 11:36:44.044210 ==========
教师模型未设置，teacher_config=None，teacher_ckpt=None
教师模型未设置，teacher_config=None，teacher_ckpt=None
2022-08-02 11:36:44,236 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': '/home/softlink/Pretrained/resnet50-19c8e357.pth'}
2022-08-02 11:36:44,237 - mmcv - INFO - load model from: /home/softlink/Pretrained/resnet50-19c8e357.pth
2022-08-02 11:36:44,237 - mmcv - INFO - Use load_from_local loader
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
2022-08-02 11:36:44,479 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2022-08-02 11:36:44,516 - mmdet - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:36:44.816237 ==========
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
教师模型未设置，teacher_config=None，teacher_ckpt=None
教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:36:45.049481 ==========
The model and loaded state dict do not match exactly

missing keys in source state_dict: bbox_head.prototype.weight

教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:36:45.140319 ==========
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:36:45.826856 ==========
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
Done (t=16.29s)
creating index...
Done (t=16.58s)
creating index...
Done (t=16.87s)
creating index...
Done (t=16.37s)
creating index...
index created!
DataIL: 当前加载图像数量为：95846 张！
index created!
DataIL: 当前加载图像数量为：95846 张！
index created!
index created!
DataIL: 当前加载图像数量为：95846 张！
DataIL: 当前加载图像数量为：95846 张！

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
Done (t=0.55s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
Done (t=0.52s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！
Done (t=0.50s)
creating index...
Done (t=0.50s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！
index created!
DataIL: 当前加载图像数量为：4952 张！

Task-2 训练图像数量: 95846 & 验证图像数量: 4952


Task-2 训练图像数量: 95846 & 验证图像数量: 4952


Task-2 训练图像数量: 95846 & 验证图像数量: 4952


Task-2 训练图像数量: 95846 & 验证图像数量: 4952

2022-08-02 11:37:06,820 - mmdet - INFO - Start running, host: kangmx@xlab2, work_dir: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_3
2022-08-02 11:37:06,820 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2022-08-02 11:37:06,820 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
Traceback (most recent call last):
  File "tools/train_increment.py", line 371, in <module>
    main()
  File "tools/train_increment.py", line 364, in main
    runner.run([train_dataloader], cfg.workflow, cur_task=tid)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 155, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 83, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 63, in run_iter
    **kwargs)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
    output = self.module.train_step(*inputs[0], **kwargs[0])
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 446, in train_step
    losses = self(**data)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
    return old_func(*args, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 206, in forward
    return self.forward_train(img, img_metas, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 318, in forward_train
    task_labels=self.LableInPCNTask)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 365, in forward_train
    student_feat=student_feat, teacher_info=teacher_info, task_labels=task_labels)#, prototype=self.prototype.weight)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 186, in new_func
    return old_func(*args, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 558, in loss
    loss_corr = self.correlation_mat(corr_teacher,corr_student, prev_length)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 1239, in correlation_mat
    self.plot_confusion_matrix(np.array(mat_student.cpu()), labels_name, 'confusion_matrix_student')
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/tensor.py", line 630, in __array__
    return self.numpy()
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
Traceback (most recent call last):
  File "tools/train_increment.py", line 371, in <module>
    main()
  File "tools/train_increment.py", line 364, in main
    runner.run([train_dataloader], cfg.workflow, cur_task=tid)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 155, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 83, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 63, in run_iter
    **kwargs)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
    output = self.module.train_step(*inputs[0], **kwargs[0])
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 446, in train_step
    losses = self(**data)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
    return old_func(*args, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 206, in forward
    return self.forward_train(img, img_metas, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 318, in forward_train
    task_labels=self.LableInPCNTask)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 365, in forward_train
    student_feat=student_feat, teacher_info=teacher_info, task_labels=task_labels)#, prototype=self.prototype.weight)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 186, in new_func
    return old_func(*args, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 558, in loss
    loss_corr = self.correlation_mat(corr_teacher,corr_student, prev_length)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 1239, in correlation_mat
    self.plot_confusion_matrix(np.array(mat_student.cpu()), labels_name, 'confusion_matrix_student')
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/tensor.py", line 630, in __array__
    return self.numpy()
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
Traceback (most recent call last):
  File "tools/train_increment.py", line 371, in <module>
    main()
  File "tools/train_increment.py", line 364, in main
    runner.run([train_dataloader], cfg.workflow, cur_task=tid)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 155, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 83, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 63, in run_iter
    **kwargs)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
    output = self.module.train_step(*inputs[0], **kwargs[0])
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 446, in train_step
    losses = self(**data)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
    return old_func(*args, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 206, in forward
    return self.forward_train(img, img_metas, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 318, in forward_train
    task_labels=self.LableInPCNTask)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 365, in forward_train
    student_feat=student_feat, teacher_info=teacher_info, task_labels=task_labels)#, prototype=self.prototype.weight)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 186, in new_func
    return old_func(*args, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 558, in loss
    loss_corr = self.correlation_mat(corr_teacher,corr_student, prev_length)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 1239, in correlation_mat
    self.plot_confusion_matrix(np.array(mat_student.cpu()), labels_name, 'confusion_matrix_student')
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/tensor.py", line 630, in __array__
    return self.numpy()
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
Traceback (most recent call last):
  File "tools/train_increment.py", line 371, in <module>
    main()
  File "tools/train_increment.py", line 364, in main
    runner.run([train_dataloader], cfg.workflow, cur_task=tid)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 155, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 83, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmcvil/task_based_runner.py", line 63, in run_iter
    **kwargs)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/parallel/distributed.py", line 52, in train_step
    output = self.module.train_step(*inputs[0], **kwargs[0])
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 446, in train_step
    losses = self(**data)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 98, in new_func
    return old_func(*args, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 206, in forward
    return self.forward_train(img, img_metas, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/detectors/deformable_detr_il.py", line 318, in forward_train
    task_labels=self.LableInPCNTask)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 365, in forward_train
    student_feat=student_feat, teacher_info=teacher_info, task_labels=task_labels)#, prototype=self.prototype.weight)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/runner/fp16_utils.py", line 186, in new_func
    return old_func(*args, **kwargs)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 558, in loss
    loss_corr = self.correlation_mat(corr_teacher,corr_student, prev_length)
  File "/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py", line 1239, in correlation_mat
    self.plot_confusion_matrix(np.array(mat_student.cpu()), labels_name, 'confusion_matrix_student')
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/tensor.py", line 630, in __array__
    return self.numpy()
RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.
Traceback (most recent call last):
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/distributed/launch.py", line 256, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/kangmx/miniconda3/envs/pth18/bin/python', '-u', 'tools/train_increment.py', '--local_rank=3', '--config=/home/kangmx/project/incremental_mmdet/configs/deformable_detr/gfl_deformable_detr_r50_8x4_1x_qoqo_il_local.py', '--work-dir=/home/softlink/experiments/il_learning/gfl_deformable_detr_20_3/', '--resume-from=', '--launcher=pytorch']' returned non-zero exit status 1.
运行总时间: 0 小时，26 分钟.
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "tools/train_increment.py", line 371, in <module>
  File "tools/train_increment.py", line 371, in <module>
  File "tools/train_increment.py", line 371, in <module>
  File "tools/train_increment.py", line 371, in <module>
                main()main()main()main()



  File "tools/train_increment.py", line 158, in main
  File "tools/train_increment.py", line 158, in main
  File "tools/train_increment.py", line 158, in main
  File "tools/train_increment.py", line 158, in main
    cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))    
        cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/utils/config.py", line 540, in dump
cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))


  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/utils/config.py", line 540, in dump
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/utils/config.py", line 540, in dump
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/utils/config.py", line 540, in dump
            f.write(self.pretty_text)    f.write(self.pretty_text)f.write(self.pretty_text)
f.write(self.pretty_text)

  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/utils/config.py", line 495, in pretty_text

  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/utils/config.py", line 495, in pretty_text
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/utils/config.py", line 495, in pretty_text
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/utils/config.py", line 495, in pretty_text
    text, _ = FormatCode(text, style_config=yapf_style, verify=True)
          File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/yapf_api.py", line 189, in FormatCode
text, _ = FormatCode(text, style_config=yapf_style, verify=True)    text, _ = FormatCode(text, style_config=yapf_style, verify=True)
text, _ = FormatCode(text, style_config=yapf_style, verify=True)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/yapf_api.py", line 189, in FormatCode

  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/yapf_api.py", line 189, in FormatCode
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/yapf_api.py", line 189, in FormatCode
    tree, style_config=style_config, lines=lines, verify=verify)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/yapf_api.py", line 151, in FormatTree
    tree, style_config=style_config, lines=lines, verify=verify)    
    tree, style_config=style_config, lines=lines, verify=verify)  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/yapf_api.py", line 151, in FormatTree
tree, style_config=style_config, lines=lines, verify=verify)

  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/yapf_api.py", line 151, in FormatTree
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/yapf_api.py", line 151, in FormatTree
    return reformatter.Reformat(_SplitSemicolons(llines), verify, lines)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 92, in Reformat
    return reformatter.Reformat(_SplitSemicolons(llines), verify, lines)
      File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 92, in Reformat
    return reformatter.Reformat(_SplitSemicolons(llines), verify, lines)return reformatter.Reformat(_SplitSemicolons(llines), verify, lines)

  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 92, in Reformat
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 92, in Reformat
    elif not _AnalyzeSolutionSpace(state):
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 498, in _AnalyzeSolutionSpace
    elif not _AnalyzeSolutionSpace(state):
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 499, in _AnalyzeSolutionSpace
        elif not _AnalyzeSolutionSpace(state):elif not _AnalyzeSolutionSpace(state):

  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 499, in _AnalyzeSolutionSpace
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 499, in _AnalyzeSolutionSpace
        count = _AddNextStateToQueue(penalty, node, False, count, p_queue)count = _AddNextStateToQueue(penalty, node, True, count, p_queue)

  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 526, in _AddNextStateToQueue
      File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 526, in _AddNextStateToQueue
count = _AddNextStateToQueue(penalty, node, True, count, p_queue)    
count = _AddNextStateToQueue(penalty, node, True, count, p_queue)  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 526, in _AddNextStateToQueue

  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/reformatter.py", line 526, in _AddNextStateToQueue
    must_split = previous_node.state.MustSplit()
      File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/format_decision_state.py", line 317, in MustSplit
must_split = previous_node.state.MustSplit()
      File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/format_decision_state.py", line 277, in MustSplit
must_split = previous_node.state.MustSplit()
      File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/format_decision_state.py", line 317, in MustSplit
must_split = previous_node.state.MustSplit()
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/format_decision_state.py", line 317, in MustSplit
        open_bracket = logical_line.IsSurroundedByBrackets(current)if (current.is_name or current.is_string) and previous.value == ',':

  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/logical_line.py", line 572, in IsSurroundedByBrackets
      File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/format_token.py", line 291, in is_string
open_bracket = logical_line.IsSurroundedByBrackets(current)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/logical_line.py", line 585, in IsSurroundedByBrackets
    open_bracket = logical_line.IsSurroundedByBrackets(current)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/yapf/yapflib/logical_line.py", line 565, in IsSurroundedByBrackets
    @property
KeyboardInterrupt
        if previous_token.value == '(':if previous_token.value == ')':

    KeyboardInterruptprevious_token = previous_token.previous_tokenKeyboardInterrupt


KeyboardInterrupt
Traceback (most recent call last):
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/subprocess.py", line 1019, in wait
    return self._wait(timeout=timeout)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/subprocess.py", line 1653, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/subprocess.py", line 1611, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
2022-08-02 11:47:22,942 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.11 (default, Jul 27 2021, 14:32:16) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 2080 Ti
CUDA_HOME: /usr/local/cuda-11.1
NVCC: Build cuda_11.1.TC455_06.29190527_0
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04) 9.4.0
PyTorch: 1.7.1+cu110
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2+cu110
OpenCV: 4.5.5
MMCV: 1.3.14
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 11.1
MMDetection: 2.23.0+90a7c74
------------------------------------------------------------

2022-08-02 11:47:35,809 - mmdet - INFO - Distributed training: True


======== Task-1(Task1) 开始, At 2022-08-02 11:47:46.864909 ==========
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '


======== Task-1(Task1) 开始, At 2022-08-02 11:47:47.687405 ==========


======== Task-1(Task1) 开始, At 2022-08-02 11:47:47.738462 ==========
教师模型未设置，teacher_config=None，teacher_ckpt=None
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
2022-08-02 11:47:48,341 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/home/softlink/dataset/COCO2017/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
img_scale_size1 = [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640]
img_scale_size2 = [
    320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768,
    800
]
img_scale_size3 = [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]
img_scale_size = [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640]
max_min_size = (640, 640)
train_pipeline_singlescale = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='Resize',
        img_scale=(640, 640),
        multiscale_mode='range',
        keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_pipeline_multiscale = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='Resize',
        img_scale=[(320, 320), (320, 352), (320, 384), (320, 416), (320, 448),
                   (320, 480), (320, 512), (320, 544), (320, 576), (320, 608),
                   (320, 640), (352, 320), (352, 352), (352, 384), (352, 416),
                   (352, 448), (352, 480), (352, 512), (352, 544), (352, 576),
                   (352, 608), (352, 640), (384, 320), (384, 352), (384, 384),
                   (384, 416), (384, 448), (384, 480), (384, 512), (384, 544),
                   (384, 576), (384, 608), (384, 640), (416, 320), (416, 352),
                   (416, 384), (416, 416), (416, 448), (416, 480), (416, 512),
                   (416, 544), (416, 576), (416, 608), (416, 640), (448, 320),
                   (448, 352), (448, 384), (448, 416), (448, 448), (448, 480),
                   (448, 512), (448, 544), (448, 576), (448, 608), (448, 640),
                   (480, 320), (480, 352), (480, 384), (480, 416), (480, 448),
                   (480, 480), (480, 512), (480, 544), (480, 576), (480, 608),
                   (480, 640), (512, 320), (512, 352), (512, 384), (512, 416),
                   (512, 448), (512, 480), (512, 512), (512, 544), (512, 576),
                   (512, 608), (512, 640), (544, 320), (544, 352), (544, 384),
                   (544, 416), (544, 448), (544, 480), (544, 512), (544, 544),
                   (544, 576), (544, 608), (544, 640), (576, 320), (576, 352),
                   (576, 384), (576, 416), (576, 448), (576, 480), (576, 512),
                   (576, 544), (576, 576), (576, 608), (576, 640), (608, 320),
                   (608, 352), (608, 384), (608, 416), (608, 448), (608, 480),
                   (608, 512), (608, 544), (608, 576), (608, 608), (608, 640),
                   (640, 320), (640, 352), (640, 384), (640, 416), (640, 448),
                   (640, 480), (640, 512), (640, 544), (640, 576), (640, 608),
                   (640, 640)],
        multiscale_mode='value',
        keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_pipeline_phdrccms = [
    dict(type='LoadImageFromFile', to_float32=True, color_type='color'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='PhotoMetricDistortion',
        brightness_delta=32,
        contrast_range=(0.5, 1.5),
        saturation_range=(0.5, 1.5),
        hue_delta=18),
    dict(
        type='RandomCenterCropPad',
        crop_size=(640, 640),
        ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),
        mean=[0, 0, 0],
        std=[1, 1, 1],
        to_rgb=True,
        test_pad_mode=None),
    dict(type='Resize', img_scale=(640, 640), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
train_pipeline_albmscale = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(
        type='Resize',
        img_scale=[(320, 320), (320, 352), (320, 384), (320, 416), (320, 448),
                   (320, 480), (320, 512), (320, 544), (320, 576), (320, 608),
                   (320, 640), (352, 320), (352, 352), (352, 384), (352, 416),
                   (352, 448), (352, 480), (352, 512), (352, 544), (352, 576),
                   (352, 608), (352, 640), (384, 320), (384, 352), (384, 384),
                   (384, 416), (384, 448), (384, 480), (384, 512), (384, 544),
                   (384, 576), (384, 608), (384, 640), (416, 320), (416, 352),
                   (416, 384), (416, 416), (416, 448), (416, 480), (416, 512),
                   (416, 544), (416, 576), (416, 608), (416, 640), (448, 320),
                   (448, 352), (448, 384), (448, 416), (448, 448), (448, 480),
                   (448, 512), (448, 544), (448, 576), (448, 608), (448, 640),
                   (480, 320), (480, 352), (480, 384), (480, 416), (480, 448),
                   (480, 480), (480, 512), (480, 544), (480, 576), (480, 608),
                   (480, 640), (512, 320), (512, 352), (512, 384), (512, 416),
                   (512, 448), (512, 480), (512, 512), (512, 544), (512, 576),
                   (512, 608), (512, 640), (544, 320), (544, 352), (544, 384),
                   (544, 416), (544, 448), (544, 480), (544, 512), (544, 544),
                   (544, 576), (544, 608), (544, 640), (576, 320), (576, 352),
                   (576, 384), (576, 416), (576, 448), (576, 480), (576, 512),
                   (576, 544), (576, 576), (576, 608), (576, 640), (608, 320),
                   (608, 352), (608, 384), (608, 416), (608, 448), (608, 480),
                   (608, 512), (608, 544), (608, 576), (608, 608), (608, 640),
                   (640, 320), (640, 352), (640, 384), (640, 416), (640, 448),
                   (640, 480), (640, 512), (640, 544), (640, 576), (640, 608),
                   (640, 640)],
        multiscale_mode='value',
        keep_ratio=True),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(
                        type='RandomBrightnessContrast',
                        brightness_limit=[-0.3, 0.3],
                        contrast_limit=[-0.3, 0.3],
                        p=1),
                    dict(
                        type='ColorJitter',
                        brightness=0.2,
                        contrast=0.2,
                        saturation=0.2,
                        hue=0.2,
                        always_apply=False,
                        p=1)
                ],
                p=0.3),
            dict(
                type='OneOf',
                transforms=[
                    dict(
                        type='GaussNoise',
                        var_limit=(30.0, 80.0),
                        mean=0,
                        per_channel=True,
                        always_apply=False,
                        p=1),
                    dict(type='MotionBlur', blur_limit=(3, 12), p=1)
                ],
                p=0.3),
            dict(
                type='Cutout',
                num_holes=72,
                max_h_size=16,
                max_w_size=16,
                fill_value=123,
                always_apply=False,
                p=0.3)
        ],
        bbox_params=None,
        keymap=None,
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline_singlescale = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(640, 640),
        flip=False,
        transforms=[
            dict(type='Resize', multiscale_mode='range', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
test_pipeline_multiscale = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=[(320, 320), (320, 352), (320, 384), (320, 416), (320, 448),
                   (320, 480), (320, 512), (320, 544), (320, 576), (320, 608),
                   (320, 640), (352, 320), (352, 352), (352, 384), (352, 416),
                   (352, 448), (352, 480), (352, 512), (352, 544), (352, 576),
                   (352, 608), (352, 640), (384, 320), (384, 352), (384, 384),
                   (384, 416), (384, 448), (384, 480), (384, 512), (384, 544),
                   (384, 576), (384, 608), (384, 640), (416, 320), (416, 352),
                   (416, 384), (416, 416), (416, 448), (416, 480), (416, 512),
                   (416, 544), (416, 576), (416, 608), (416, 640), (448, 320),
                   (448, 352), (448, 384), (448, 416), (448, 448), (448, 480),
                   (448, 512), (448, 544), (448, 576), (448, 608), (448, 640),
                   (480, 320), (480, 352), (480, 384), (480, 416), (480, 448),
                   (480, 480), (480, 512), (480, 544), (480, 576), (480, 608),
                   (480, 640), (512, 320), (512, 352), (512, 384), (512, 416),
                   (512, 448), (512, 480), (512, 512), (512, 544), (512, 576),
                   (512, 608), (512, 640), (544, 320), (544, 352), (544, 384),
                   (544, 416), (544, 448), (544, 480), (544, 512), (544, 544),
                   (544, 576), (544, 608), (544, 640), (576, 320), (576, 352),
                   (576, 384), (576, 416), (576, 448), (576, 480), (576, 512),
                   (576, 544), (576, 576), (576, 608), (576, 640), (608, 320),
                   (608, 352), (608, 384), (608, 416), (608, 448), (608, 480),
                   (608, 512), (608, 544), (608, 576), (608, 608), (608, 640),
                   (640, 320), (640, 352), (640, 384), (640, 416), (640, 448),
                   (640, 480), (640, 512), (640, 544), (640, 576), (640, 608),
                   (640, 640)],
        flip=True,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(type='Resize', img_scale=(640, 640), keep_ratio=True),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=1),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(640, 640),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=1),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
which = ['', '_mini1k', '_mini2k', '_mini5k', '_mini2w', '_mini3w', '_mini5w']
trainwhich = ''
valwhich = ''
data = dict(
    samples_per_gpu=4,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file=
        '/home/softlink/dataset/COCO2017/annotations/instances_train2017.json',
        img_prefix='/home/softlink/dataset/COCO2017/train2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(
                type='Resize',
                img_scale=(640, 640),
                multiscale_mode='range',
                keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ],
        test_mode=False,
        catsplit=(40, 40),
        catload=(1, 0),
        catpred='prev-cur',
        catwise=True,
        imgpercent=1),
    val=dict(
        type='CocoDataset',
        ann_file=
        '/home/softlink/dataset/COCO2017/annotations/instances_val2017.json',
        img_prefix='/home/softlink/dataset/COCO2017/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(640, 640),
                flip=False,
                transforms=[
                    dict(
                        type='Resize',
                        multiscale_mode='range',
                        keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        test_mode=True,
        catsplit=(40, 40),
        catload=(1, 0),
        catpred='only-cur',
        catwise=True,
        imgpercent=1),
    test=dict(
        type='CocoDataset',
        ann_file=
        '/home/softlink/dataset/COCO2017/annotations/instances_val2017.json',
        img_prefix='/home/softlink/dataset/COCO2017/val2017/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(640, 640),
                flip=False,
                transforms=[
                    dict(
                        type='Resize',
                        multiscale_mode='range',
                        keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        test_mode=True,
        catsplit=(40, 40),
        catload=(1, 0),
        catpred='prev-cur',
        catwise=True,
        imgpercent=1),
    cat_split_load='auto')
evaluation = dict(interval=1, metric='bbox')
checkpoint_config = dict(interval=1)
log_config = dict(
    interval=1,
    hooks=[dict(type='TextLoggerHook'),
           dict(type='TensorboardLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = ''
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
task = dict(
    resume_by_task=1,
    resume_by_epoch='',
    Task1=dict(
        load_teacher=0,
        load_student=1,
        teacher_config=
        '/home/kangmx/project/incremental_mmdet/configs/deformable_detr/gfl_deformable_detr_r50_8x4_1x_qoqo_il_local.py',
        teacher_ckpt=
        '/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth',
        student_ckpt=
        '/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth'
    ))
model = dict(
    type='DeformableDETR_il',
    teacher_config=None,
    teacher_ckpt=None,
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=False),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(
            type='Pretrained',
            checkpoint='/home/softlink/Pretrained/resnet50-19c8e357.pth')),
    neck=dict(
        type='ChannelMapper',
        in_channels=[512, 1024, 2048],
        kernel_size=1,
        out_channels=256,
        act_cfg=None,
        norm_cfg=dict(type='GN', num_groups=32),
        num_outs=4),
    bbox_head=dict(
        type='GFLDeformableDETRHead_il',
        num_query=300,
        num_classes=80,
        in_channels=2048,
        sync_cls_avg_factor=True,
        as_two_stage=False,
        transformer=dict(
            type='DeformableDetrTransformer',
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention', embed_dims=256),
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'ffn', 'norm'))),
            decoder=dict(
                type='DeformableDetrTransformerDecoder',
                num_layers=6,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.1),
                        dict(
                            type='MultiScaleDeformableAttention',
                            embed_dims=256)
                    ],
                    feedforward_channels=1024,
                    ffn_dropout=0.1,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='QualityFocalLoss',
            use_sigmoid=True,
            beta=2.0,
            loss_weight=2.0),
        loss_dfl=dict(type='DistributionFocalLoss', loss_weight=0.5),
        loss_bbox=dict(type='L1Loss', loss_weight=5.0),
        loss_iou=dict(type='GIoULoss', loss_weight=2.0),
        cates_distill='hard + teacher-first',
        locat_distill='',
        memory_distill='',
        feats_distill='corr',
        loss_kd=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='mean'),
        loss_ld_bbox=dict(
            type='SmoothL1Loss', loss_weight=10, reduction='mean'),
        loss_ld_logit=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='mean'),
        loss_fd=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_memory=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_fg_feature=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_bg_feature=dict(
            type='KnowledgeDistillationKLDivLoss',
            loss_weight=1,
            T=2,
            reduction='sum'),
        loss_corr=dict(type='MSELoss', loss_weight=1, reduction='mean')),
    train_cfg=dict(
        assigner=dict(
            type='GFLHungarianAssigner',
            cls_cost=dict(type='QualityFocalLossCost', weight=2.0),
            reg_cost=dict(type='BBoxL1Cost', weight=5.0, box_format='xywh'),
            iou_cost=dict(type='IoUCost', iou_mode='giou', weight=2.0))),
    test_cfg=dict(max_per_img=100, score_thr=0.0),
    teacher_test_cfg=dict(min_bbox_size=0, score_thr=0.3, max_per_img=100))
catsplit = (40, 40)
catload = (1, 0)
cat_split_load = 'auto'
task_nums = 2
optimizer = [
    dict(type='SGD', lr=0.0, momentum=0.9, weight_decay=0.0001),
    dict(type='SGD', lr=0.0, momentum=0.9, weight_decay=0.0001)
]
optimizer_config = dict(grad_clip=None)
lr_config = [
    dict(
        policy='step',
        warmup='linear',
        warmup_iters=1500,
        warmup_ratio=0.01,
        step=[8, 11]),
    dict(
        policy='step',
        warmup='linear',
        warmup_iters=1500,
        warmup_ratio=0.01,
        step=[8, 11])
]
runner = [
    dict(
        type='TaskEpochBasedRunner',
        max_epochs=12,
        max_tasks=2,
        save_teacher=False),
    dict(
        type='TaskEpochBasedRunner',
        max_epochs=12,
        max_tasks=2,
        save_teacher=False)
]
work_dir = '/home/softlink/experiments/il_learning/gfl_deformable_detr_20_3/'
auto_resume = False
gpu_ids = range(0, 4)

2022-08-02 11:47:48,342 - mmdet - INFO - Set random seed to 111, deterministic: False


======== Task-1(Task1) 开始, At 2022-08-02 11:47:48.342788 ==========
教师模型未设置，teacher_config=None，teacher_ckpt=None
教师模型未设置，teacher_config=None，teacher_ckpt=None
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `feedforward_channels` in BaseTransformerLayer has been deprecated, now you should set `feedforward_channels` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_dropout` in BaseTransformerLayer has been deprecated, now you should set `ffn_drop` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:47:48.685607 ==========
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:349: UserWarning: The arguments `ffn_num_fcs` in BaseTransformerLayer has been deprecated, now you should set `num_fcs` and other FFN related arguments to a dict named `ffn_cfgs`. 
  f'The arguments `{ori_name}` in BaseTransformerLayer '
/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/mmcv/cnn/bricks/transformer.py:92: UserWarning: The arguments `dropout` in MultiheadAttention has been deprecated, now you can separately set `attn_drop`(float), proj_drop(float), and `dropout_layer`(dict) 
  warnings.warn('The arguments `dropout` in MultiheadAttention '
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
教师模型未设置，teacher_config=None，teacher_ckpt=None
2022-08-02 11:47:49,277 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': '/home/softlink/Pretrained/resnet50-19c8e357.pth'}
2022-08-02 11:47:49,277 - mmcv - INFO - load model from: /home/softlink/Pretrained/resnet50-19c8e357.pth
2022-08-02 11:47:49,278 - mmcv - INFO - Use load_from_local loader
教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:47:49.478529 ==========
2022-08-02 11:47:49,532 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:47:49.534268 ==========
2022-08-02 11:47:49,569 - mmdet - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
学生模型权值加载：/home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth
Use load_from_local loader
The model and loaded state dict do not match exactly

missing keys in source state_dict: bbox_head.prototype.weight

教师模型未设置

====== Task-1(Task1) 跳过，Resume From Prev-Student-Model CheckPoint: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_1/40_task_1_epoch_12.pth


======== Task-2(Task2) 开始, At 2022-08-02 11:47:50.169668 ==========
教师模型已设置，TrainVal：val，权值加载：byModel
Param Nums of Model: 39880856

DataIL: 训练集, 任务划分：(40, 40), 任务加载：[0, 1]
DataIL: 预测类别 80 个，加载类别 40 个: ('kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_train2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
Done (t=17.01s)
creating index...
Done (t=16.87s)
creating index...
Done (t=16.98s)
creating index...
Done (t=16.68s)
creating index...
index created!
DataIL: 当前加载图像数量为：95846 张！
index created!
index created!
DataIL: 当前加载图像数量为：95846 张！
DataIL: 当前加载图像数量为：95846 张！
index created!
DataIL: 当前加载图像数量为：95846 张！

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
Done (t=0.52s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...

DataIL: 验证集, 任务划分：(40, 40), 任务加载：[1, 1]
DataIL: 预测类别 80 个，加载类别 80 个: ('airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'fork', 'frisbee', 'giraffe', 'hair drier', 'handbag', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'laptop', 'microwave', 'motorcycle', 'mouse', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'remote', 'sandwich', 'scissors', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'tie', 'toaster', 'toilet', 'toothbrush', 'traffic light', 'train', 'truck', 'tv', 'umbrella', 'vase', 'wine glass', 'zebra')
/home/kangmx/project/incremental_mmdet/mmdet/datasets/custom.py:139: UserWarning: The used MMCV version does not have get_local_path. We treat the /home/softlink/dataset/COCO2017/annotations/instances_val2017.json as local paths and it might cause errors if the path is not a local path. Please use MMCV>= 1.3.16 if you meet errors.
  'The used MMCV version does not have get_local_path. '
loading annotations into memory...
Done (t=0.51s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！
Done (t=0.55s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！
Done (t=0.50s)
creating index...
index created!
DataIL: 当前加载图像数量为：4952 张！

Task-2 训练图像数量: 95846 & 验证图像数量: 4952


Task-2 训练图像数量: 95846 & 验证图像数量: 4952

Task-2 训练图像数量: 95846 & 验证图像数量: 4952



Task-2 训练图像数量: 95846 & 验证图像数量: 4952

2022-08-02 11:48:11,511 - mmdet - INFO - Start running, host: kangmx@xlab2, work_dir: /home/softlink/experiments/il_learning/gfl_deformable_detr_20_3
2022-08-02 11:48:11,511 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2022-08-02 11:48:11,511 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
2022-08-02 11:54:56,118 - mmdet - INFO - Epoch [1][1/5992]	lr: 0.000e+00, eta: 336 days, 15:47:40, time: 404.535, data_time: 2.813, memory: 5742, loss_corr: 0.0013, loss_cls: 0.3499, loss_bbox: 0.8266, loss_iou: 1.0673, loss_dfl: 1.0214, d0.loss_cls: 0.3916, d0.loss_bbox: 0.8476, d0.loss_iou: 1.0630, d0.loss_dfl: 1.0211, d1.loss_cls: 0.3704, d1.loss_bbox: 0.8440, d1.loss_iou: 1.0568, d1.loss_dfl: 1.0211, d2.loss_cls: 0.3760, d2.loss_bbox: 0.8240, d2.loss_iou: 1.0458, d2.loss_dfl: 1.0223, d3.loss_cls: 0.4050, d3.loss_bbox: 0.7892, d3.loss_iou: 1.0374, d3.loss_dfl: 1.0217, d4.loss_cls: 0.3708, d4.loss_bbox: 0.8238, d4.loss_iou: 1.0641, d4.loss_dfl: 1.0222, loss: 19.6844
2022-08-02 11:55:11,247 - mmdet - INFO - Epoch [1][2/5992]	lr: 0.000e+00, eta: 174 days, 14:58:10, time: 15.133, data_time: 0.325, memory: 7280, loss_corr: 0.0001, loss_cls: 0.3343, loss_bbox: 0.6675, loss_iou: 1.1577, loss_dfl: 1.0229, d0.loss_cls: 0.3572, d0.loss_bbox: 0.6476, d0.loss_iou: 1.1632, d0.loss_dfl: 1.0218, d1.loss_cls: 0.3632, d1.loss_bbox: 0.6346, d1.loss_iou: 1.1486, d1.loss_dfl: 1.0246, d2.loss_cls: 0.3442, d2.loss_bbox: 0.6441, d2.loss_iou: 1.1555, d2.loss_dfl: 1.0238, d3.loss_cls: 0.3628, d3.loss_bbox: 0.6342, d3.loss_iou: 1.1364, d3.loss_dfl: 1.0239, d4.loss_cls: 0.3743, d4.loss_bbox: 0.6647, d4.loss_iou: 1.1273, d4.loss_dfl: 1.0228, loss: 19.0573
/home/kangmx/project/incremental_mmdet/mmdet/models/dense_heads/gfl_deformable_detr_head_il.py:1202: RuntimeWarning: invalid value encountered in true_divide
  cm = cm / cm.sum(axis=1)[:, np.newaxis]  # 归一化
Traceback (most recent call last):
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/distributed/launch.py", line 260, in <module>
    main()
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/site-packages/torch/distributed/launch.py", line 253, in main
    process.wait()
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/subprocess.py", line 1019, in wait
    return self._wait(timeout=timeout)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/subprocess.py", line 1653, in _wait
    (pid, sts) = self._try_wait(0)
  File "/home/kangmx/miniconda3/envs/pth18/lib/python3.7/subprocess.py", line 1611, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
运行总时间: 0 小时，17 分钟.
